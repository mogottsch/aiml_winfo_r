---
output:
  pdf_document: default
  html_document: default
---
**Disclaimer**: It is probably easier to read this assignment as `.Rmd` and not as PDF, because there are a lot of outputs and plots, which can get a little overwhelming when not viewed through RStudio.

# Exercise 1

In this exercise we use the College data set from the ISLR package. We predict the number of applications received using the other variables.

```{r, echo=FALSE}
set.seed(4711)
```

```{r, message=FALSE}
library(ISLR)
library(tidymodels)

library(tidymodels)
library(funModeling)
library(ISLR)
library(vip)
library(forcats)
library(GGally)

?ISLR::College
```

```{r}
College <- tibble(College)
College
```


```{r}
basic_eda <- function(data) {
  glimpse(data)
  print(status(data))
  freq(data)
  print(profiling_num(data))
  plot_num(data)
  describe(data)
}

basic_eda(College)
```
Split the data set into a training set and a test set.
```{r}
College_split <- initial_split(College, strata = Apps, prop = 0.5)
College_split
College_train <- training(College_split)
College_test <- testing(College_split)
```

Fit a linear model using least squares on the training set, and report the test error obtained.
```{r}
lm_spec <- linear_reg() %>%
  set_mode("regression") %>%
  set_engine("lm")
```


```{r}
lm_recipe <-
  recipe(formula = Apps ~ ., data = College_train) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_normalize(all_numeric_predictors())
```

**Note**: We use the variables `Accept` and `Enroll` as independent variables
here. These variables describe the number of accepted applicants and the
number of new enrolled students, respectively. Depending on the application one
might not know these variables when predicting the the number of applications.

```{r}
lm_workflow <- workflow() %>%
  add_recipe(lm_recipe) %>%
  add_model(lm_spec)
```

```{r}
lm_fit <- lm_workflow %>% fit(College_train)
```

```{r}
augment(lm_fit, new_data = College_test) %>%
  select(Apps, .pred)


augment(lm_fit, new_data = College_test) %>%
  rmse(truth = Apps, estimate = .pred)
```
The rmse of the test error is 1183.

Out of curiosity, let's look at the feature importance.

```{r}
lm_fit %>%
  extract_fit_parsnip() %>%
  vi(lambda = best_penalty$penalty) %>%
  mutate(
    Importance = abs(Importance),
    Variable = fct_reorder(Variable, Importance)
  ) %>%
  ggplot(aes(x = Importance, y = Variable, fill = Sign)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL)
```


Fit a ridge regression model on the training set, with \(\lambda\) chosen by cross-validation. Report the test error obtained.
```{r}
ridge_spec <- linear_reg(mixture = 0, penalty = tune()) %>%
  set_mode("regression") %>%
  set_engine("glmnet")

ridge_workflow <- workflow() %>%
  add_recipe(recipe = lm_recipe) %>%
  add_model(ridge_spec)
```

```{r}
College_fold <- vfold_cv(College_train, v = 10)
College_fold
```

```{r}
penalty_grid <- grid_regular(
  penalty(range = c(-5, 5)), # penalty automatically uses log scale
  levels = 50
)
penalty_grid
```

```{r}
tune_res <- tune_grid(
  ridge_workflow,
  resamples = College_fold,
  grid = penalty_grid
)

tune_res
```

```{r}
autoplot(tune_res)
```

```{r}
best_penalty <- select_best(tune_res, metric = "rmse")
best_penalty
```

```{r}
ridge_final <- finalize_workflow(ridge_workflow, best_penalty)
ridge_final_fit <- ridge_final %>% fit(College_train)
```

```{r}
augment(ridge_final_fit, new_data = College_test) %>%
  rmse(truth = Apps, estimate = .pred)
```

The test error is 1178, which is slightly lower than a linear model without
regularization.

Again let's also look at the feature importance.

```{r}
ridge_final_fit %>%
  extract_fit_parsnip() %>%
  vi(lambda = best_penalty$penalty) %>%
  mutate(
    Importance = abs(Importance),
    Variable = fct_reorder(Variable, Importance)
  ) %>%
  ggplot(aes(x = Importance, y = Variable, fill = Sign)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL)
```


Fit a lasso model on the training set, with \(\lambda\) chosen by
cross-validation. Report the test error obtained, along with the number of
non-zero coefficient estimates.


```{r}
lasso_spec <- linear_reg(mixture = 1, penalty = tune()) %>%
  set_mode("regression") %>%
  set_engine("glmnet")

lasso_workflow <- workflow() %>%
  add_recipe(recipe = lm_recipe) %>%
  add_model(lasso_spec)
```

```{r}
penalty_grid <- grid_regular(
  penalty(range = c(-5, 2)),
  levels = 50
)
```

```{r}
tune_res <- tune_grid(
  lasso_workflow,
  resamples = College_fold,
  grid = penalty_grid
)
tune_res
```

```{r}
best_penalty <- select_best(tune_res, metric = "rmse")
best_penalty
```

```{r}
lasso_final <- finalize_workflow(lasso_workflow, best_penalty)

lasso_final_fit <- fit(lasso_final, data = College_train)
```

```{r}
augment(lasso_final_fit, new_data = College_test) %>%
  rmse(truth = Apps, estimate = .pred)
```
The rmse is 1192.677, which is worse than Ridge and a simple linear model.

```{r}
lasso_final_fit %>%
  extract_fit_parsnip() %>%
  vi(lambda = best_penalty$penalty) %>%
  mutate(
    Importance = abs(Importance),
    Variable = fct_reorder(Variable, Importance)
  ) %>%
  ggplot(aes(x = Importance, y = Variable, fill = Sign)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL)
```
# Exercise 2

Fit some of the non-linear models (polynomial regression, splines) discussed in
the lecture to the Auto data set. 
Is there evidence for non-linear relationships in this data set? Create some
informative plots to justify your answer.

```{r}
Auto <- tibble(Auto)

basic_eda(Auto)
```

```{r}
ggpairs(Auto[, names(Auto) != "name"])
```
There are some non linear looking relationships. 
Let's look at `mpg` and `horsepower` 

We will not perform train-test-split or hyper-parameter tuning here, as we are
only interested in exploring the relations.


```{r}
# Recipe
polynomial_recipe <-
  recipe(formula = mpg ~ horsepower, data = Auto) %>%
  step_poly(all_numeric_predictors(), degree = 2, options = list(raw = TRUE)) %>%
  step_normalize(all_predictors())

# Specification
polynomial_spec <-
  linear_reg(mixture = 1, penalty = tune()) %>%
  set_mode("regression") %>%
  set_engine("lm")


# Workflow
polynomial_workflow <- workflow() %>%
  add_recipe(polynomial_recipe) %>%
  add_model(polynomial_spec)

# Finalize model
polynomial_fit <- fit(polynomial_workflow, data = Auto)
```

```{r}
horsepower_min <- min(Auto$horsepower)
horsepower_max <- max(Auto$horsepower)
horsepower_range <- tibble(horsepower = seq(horsepower_min, horsepower_max))
horsepower_range
```

```{r}
regression_lines <- bind_cols(
  predict(polynomial_fit, new_data = horsepower_range),
  horsepower_range
)

Auto %>%
  ggplot(aes(horsepower, mpg)) +
  geom_point(alpha = 0.2) +
  geom_line(aes(y = .pred), data = regression_lines, color = "blue")
```
We can see that the relation between `mpg` and `horsepower` is nicely fit by a
polynomial of degree 2, which would not be possible with a simple linear
regression.


```{r}
# Recipe
spline_recipe <-
  recipe(formula = mpg ~ horsepower, data = Auto) %>%
  step_bs(horsepower, options = list(knots = 70, 100, 130, 160, 190, 220))

# Specification
spline_spec <-
  linear_reg(mixture = 1, penalty = tune()) %>%
  set_mode("regression") %>%
  set_engine("lm")


# Workflow
spline_workflow <- workflow() %>%
  add_recipe(spline_recipe) %>%
  add_model(spline_spec)

# Finalize model
spline_fit <- fit(spline_workflow, data = Auto)
```

```{r}
regression_lines <- bind_cols(
  predict(spline_fit, new_data = horsepower_range),
  horsepower_range
)

Auto %>%
  ggplot(aes(horsepower, mpg)) +
  geom_point(alpha = 0.2) +
  geom_line(aes(y = .pred), data = regression_lines, color = "blue")
```
We see that the fit created by splines is very similar to the polynomial
regression. The only noticeable difference is that splines seem to act less
extreme at the borders of our data, e.g. `horsepower > 200`.



# Exercise 3
The Wage data set contains a number of features, such as marital status (marital
), job class (jobclass), and others.
Explore the relationships between some of these predictors and wage, and use
non-linear fitting techniques in order to fit flexible models to the data.
Create plots of the results obtained, and write a summary of your findings.

```{r}
Wage <- tibble(Wage)

basic_eda(Wage)
```

```{r}
Wage_split <- initial_split(Wage, strata = wage, prop = 0.5)
Wage_split
Wage_train <- training(Wage_split)
Wage_test <- testing(Wage_split)

Wage_fold <- vfold_cv(Wage_train, v = 10)
Wage_fold
```

```{r}
colnames <- colnames(Wage)
colnames <- colnames[colnames != "wage"]

for (colname in colnames) {
  pl <- Wage %>%
    ggplot(aes_string(x = colname, y = "wage")) +
    geom_point(alpha = 0.2)
  print(pl)
}
```


```{r}
# Recipe
lm_pl_recipe <-
  recipe(formula = wage ~ age, data = Wage_train) %>%
  step_poly(age, degree = 2, options = list(raw = TRUE)) %>%
  step_normalize(all_predictors())

# Specification
lm_pl_spec <-
  linear_reg() %>%
  set_mode("regression") %>%
  set_engine("lm")

# Workflow
lm_pl_workflow <- workflow() %>%
  add_recipe(lm_pl_recipe) %>%
  add_model(lm_pl_spec)

# Finalize model
lm_pl_fit <- fit(lm_pl_workflow, data = Wage_train)

# Check RMSE
augment(lm_pl_fit, new_data = Wage_test) %>%
  rmse(truth = wage, estimate = .pred)
tidy(lm_pl_fit)
```


```{r}
age_min <- min(Wage$age)
age_max <- max(Wage$age)
age_range <- tibble(age = seq(age_min, age_max))
age_range
```

```{r}
regression_lines <- bind_cols(
  predict(lm_pl_fit, new_data = age_range),
  age_range
)

Wage %>%
  ggplot(aes(age, wage)) +
  geom_point(alpha = 0.2) +
  geom_line(aes(y = .pred), data = regression_lines, color = "blue")
```


All the other variables are categorical. Hot encoding these variables basically results in a "piecewise non-linear" function. However, exploring this most likely is not very interesting.
Therefor we will now test splines also on the relationships of age and wage.

```{r}
min(Wage$age)
```

```{r}
spline_recipe <- recipe(formula = wage ~ age, data = Wage_train) %>%
  step_bs(age, options = list(knots = 20, 30, 40, 50, 60, 70))

# Specification
spline_spec <-
  linear_reg() %>%
  set_mode("regression") %>%
  set_engine("lm")

# Workflow
spline_workflow <- workflow() %>%
  add_recipe(spline_recipe) %>%
  add_model(spline_spec)

# Finalize model
spline_fit <- fit(spline_workflow, data = Wage_train)

# Check RMSE
augment(spline_fit, new_data = Wage_test) %>%
  rmse(truth = wage, estimate = .pred)
```


```{r}
regression_lines <- bind_cols(
  predict(spline_fit, new_data = age_range),
  age_range
)

Wage %>%
  ggplot(aes(age, wage)) +
  geom_point(alpha = 0.2) +
  geom_line(aes(y = .pred), data = regression_lines, color = "blue")
```


Both the polynomial regression as well as splines capture the relationship
between age and wage better than a simple linear regression. We can see that the
splines fit the data even better than the polynomial regression, especially at
the border regions.